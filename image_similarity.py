import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
import time

class ImageSimilaritySystem:
    """
    Syst√®me de recherche d'images similaires utilisant l'extraction de features
    et diff√©rentes m√©triques de similarit√©.
    """
    
    def __init__(self, dataset_path="archive/animals/", image_size=(128, 128)):
        """
        Initialise le syst√®me de recherche d'images.

        Args:
            dataset_path: Chemin vers le dossier contenant les images (par d√©faut: archive/animals/)
            image_size: Taille de redimensionnement des images (largeur, hauteur)
        """
        self.dataset_path = dataset_path
        self.image_size = image_size
        self.images = []
        self.image_paths = []
        self.features = None
        self.scaler = StandardScaler()

        # T√©l√©charger le dataset si n√©cessaire
        self._download_dataset_if_needed()

    def _download_dataset_if_needed(self):
        """
        T√©l√©charge le dataset depuis Kaggle si le dossier n'existe pas ou est vide.
        """
        # V√©rifier si le dossier existe et contient des images
        has_images = False
        if os.path.exists(self.dataset_path):
            supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')
            for root, dirs, files in os.walk(self.dataset_path):
                for file in files:
                    if file.lower().endswith(supported_formats):
                        has_images = True
                        break
                if has_images:
                    break

        if not has_images:
            print("üì• T√©l√©chargement du dataset depuis Kaggle...")
            start_time = time.time()
            try:
                # Cr√©er le dossier parent si n√©cessaire
                os.makedirs(os.path.dirname(self.dataset_path), exist_ok=True)

                # T√©l√©charger le dataset
                import kaggle
                kaggle.api.dataset_download_files(
                    'ashishsaxena2209/animal-image-datasetdog-cat-and-panda',
                    path=os.path.dirname(self.dataset_path),
                    unzip=True
                )

                elapsed = time.time() - start_time
                print(f"‚úÖ Dataset t√©l√©charg√© dans {self.dataset_path} en {elapsed:.2f}s")

            except Exception as e:
                print(f"‚ùå Erreur lors du t√©l√©chargement: {e}")
                print("V√©rifiez que vous avez configur√© votre API Kaggle (kaggle.json)")
                print("Ou placez manuellement le dataset dans le dossier archive/")
                raise
        else:
            print("‚úÖ Dataset d√©j√† pr√©sent")
        
    def load_dataset(self):
        """
        Charge toutes les images du dataset depuis le dossier sp√©cifi√©.
        Supporte les sous-dossiers (train, test, validation).
        """
        print("üìÅ Chargement du dataset...")
        supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')
        
        # Parcourir tous les sous-dossiers
        for root, dirs, files in os.walk(self.dataset_path):
            for file in files:
                if file.lower().endswith(supported_formats):
                    img_path = os.path.join(root, file)
                    self.image_paths.append(img_path)
        
        print(f"‚úÖ {len(self.image_paths)} images trouv√©es dans le dataset")
        
    def preprocess_images(self):
        """
        Pr√©traite toutes les images : redimensionnement et normalisation.
        """
        print("üîÑ Pr√©traitement des images...")
        start_time = time.time()
        
        for idx, img_path in enumerate(self.image_paths):
            try:
                # Charger l'image
                img = Image.open(img_path).convert('RGB')
                
                # Redimensionner
                img = img.resize(self.image_size, Image.Resampling.LANCZOS)
                
                # Convertir en array numpy et normaliser [0, 1]
                img_array = np.array(img) / 255.0
                
                self.images.append(img_array)
                
                if (idx + 1) % 100 == 0:
                    print(f"   Trait√©: {idx + 1}/{len(self.image_paths)} images")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lors du traitement de {img_path}: {e}")
        
        self.images = np.array(self.images)
        elapsed = time.time() - start_time
        print(f"‚úÖ Pr√©traitement termin√© en {elapsed:.2f}s")
        
    def extract_features(self, method='histogram'):
        """
        Extrait les caract√©ristiques des images.

        Args:
            method: 'histogram' pour histogramme de couleurs
                   'raw' pour pixels bruts aplatis
                   'color_moments' pour moments statistiques de couleur
        """
        if len(self.images) == 0:
            print("‚ö†Ô∏è  Aucune image trouv√©e dans le dataset. Impossible d'extraire les features.")
            return

        print(f"üéØ Extraction des features (m√©thode: {method})...")
        start_time = time.time()

        if method == 'histogram':
            # Histogramme de couleurs RGB (32 bins par canal)
            features_list = []
            for img in self.images:
                hist_r = np.histogram(img[:,:,0], bins=32, range=(0, 1))[0]
                hist_g = np.histogram(img[:,:,1], bins=32, range=(0, 1))[0]
                hist_b = np.histogram(img[:,:,2], bins=32, range=(0, 1))[0]
                features = np.concatenate([hist_r, hist_g, hist_b])
                features_list.append(features)
            self.features = np.array(features_list)

        elif method == 'raw':
            # Pixels bruts aplatis
            self.features = self.images.reshape(len(self.images), -1)

        elif method == 'color_moments':
            # Moments statistiques (moyenne, variance, skewness) par canal
            features_list = []
            for img in self.images:
                moments = []
                for c in range(3):  # Pour chaque canal RGB
                    channel = img[:,:,c].flatten()
                    mean = np.mean(channel)
                    std = np.std(channel)
                    skew = np.mean((channel - mean) ** 3) / (std ** 3 + 1e-10)
                    moments.extend([mean, std, skew])
                features_list.append(moments)
            self.features = np.array(features_list)

        # Normalisation des features
        self.features = self.scaler.fit_transform(self.features)

        elapsed = time.time() - start_time
        print(f"‚úÖ Features extraites: {self.features.shape} en {elapsed:.2f}s")
        
    def compute_similarity(self, reference_idx, method='cosine'):
        """
        Calcule la similarit√© entre une image de r√©f√©rence et toutes les autres.
        
        Args:
            reference_idx: Index de l'image de r√©f√©rence
            method: 'cosine' pour similarit√© cosinus
                   'euclidean' pour distance euclidienne
        
        Returns:
            Array des scores de similarit√©
        """
        reference_features = self.features[reference_idx].reshape(1, -1)
        
        if method == 'cosine':
            # Similarit√© cosinus (1 = identique, 0 = orthogonal)
            similarities = cosine_similarity(reference_features, self.features)[0]
            
        elif method == 'euclidean':
            # Distance euclidienne (0 = identique, plus grand = plus diff√©rent)
            # On inverse pour avoir un score de similarit√©
            distances = euclidean_distances(reference_features, self.features)[0]
            # Normaliser et inverser: similarit√© = 1 / (1 + distance)
            similarities = 1 / (1 + distances)
        
        return similarities
    
    def find_top_k_similar(self, reference_idx, k=5, similarity_method='cosine'):
        """
        Trouve les K images les plus similaires √† une image de r√©f√©rence.
        
        Args:
            reference_idx: Index de l'image de r√©f√©rence
            k: Nombre d'images similaires √† retourner
            similarity_method: M√©thode de calcul de similarit√©
        
        Returns:
            indices: Indices des K images les plus similaires
            scores: Scores de similarit√© correspondants
        """
        similarities = self.compute_similarity(reference_idx, similarity_method)
        
        # Trier par similarit√© d√©croissante et prendre les top-k
        # (on exclut l'image elle-m√™me si elle est dans les r√©sultats)
        top_indices = np.argsort(similarities)[::-1]
        
        # Filtrer l'image de r√©f√©rence elle-m√™me
        top_indices = [idx for idx in top_indices if idx != reference_idx][:k]
        top_scores = similarities[top_indices]
        
        return top_indices, top_scores
    
    def display_results(self, reference_idx, top_indices, top_scores, 
                       similarity_method, feature_method):
        """
        Affiche l'image de r√©f√©rence et les images similaires trouv√©es.
        """
        k = len(top_indices)
        fig, axes = plt.subplots(2, k + 1, figsize=(3 * (k + 1), 6))
        
        # Titre principal
        fig.suptitle(f'Recherche d\'images similaires\n'
                    f'Features: {feature_method} | Similarit√©: {similarity_method}',
                    fontsize=14, fontweight='bold')
        
        # Image de r√©f√©rence
        axes[0, 0].imshow(self.images[reference_idx])
        axes[0, 0].set_title('Image de\nR√âF√âRENCE', fontweight='bold', color='red')
        axes[0, 0].axis('off')
        
        ref_name = os.path.basename(self.image_paths[reference_idx])
        axes[1, 0].text(0.5, 0.5, f'{ref_name}', 
                       ha='center', va='center', wrap=True, fontsize=8)
        axes[1, 0].axis('off')
        
        # Images similaires
        for i, (idx, score) in enumerate(zip(top_indices, top_scores)):
            axes[0, i + 1].imshow(self.images[idx])
            axes[0, i + 1].set_title(f'Top-{i+1}\nScore: {score:.4f}', 
                                    fontsize=10)
            axes[0, i + 1].axis('off')
            
            img_name = os.path.basename(self.image_paths[idx])
            axes[1, i + 1].text(0.5, 0.5, f'{img_name}', 
                               ha='center', va='center', wrap=True, fontsize=8)
            axes[1, i + 1].axis('off')
        
        plt.tight_layout()
        plt.show()
    
    def compare_methods(self, reference_idx, k=5):
        """
        Compare diff√©rentes m√©thodes de similarit√© et d'extraction de features.
        """
        print("\n" + "="*70)
        print("üî¨ COMPARAISON DES M√âTHODES")
        print("="*70)
        
        feature_methods = ['histogram', 'color_moments']
        similarity_methods = ['cosine', 'euclidean']
        
        results = {}
        
        for feat_method in feature_methods:
            print(f"\nüìä Extraction de features: {feat_method}")
            self.extract_features(method=feat_method)
            
            for sim_method in similarity_methods:
                print(f"   ‚Ü≥ Calcul de similarit√©: {sim_method}")
                start_time = time.time()
                
                top_indices, top_scores = self.find_top_k_similar(
                    reference_idx, k, sim_method
                )
                
                elapsed = time.time() - start_time
                
                key = f"{feat_method}_{sim_method}"
                results[key] = {
                    'indices': top_indices,
                    'scores': top_scores,
                    'time': elapsed
                }
                
                print(f"      ‚è±Ô∏è  Temps: {elapsed:.4f}s")
                print(f"      üìà Scores moyens: {np.mean(top_scores):.4f}")
                
                # Afficher les r√©sultats
                self.display_results(reference_idx, top_indices, top_scores,
                                   sim_method, feat_method)
        
        return results
    
    def analyze_performance(self, results):
        """
        Analyse et affiche un r√©sum√© des performances des diff√©rentes m√©thodes.
        """
        print("\n" + "="*70)
        print("üìä ANALYSE DE PERFORMANCE")
        print("="*70)

        for method_name, data in results.items():
            parts = method_name.split('_')
            feat = '_'.join(parts[:-1])
            sim = parts[-1]
            print(f"\nüî∏ {feat.upper()} + {sim.upper()}")
            print(f"   Temps d'ex√©cution: {data['time']:.4f}s")
            print(f"   Score moyen: {np.mean(data['scores']):.4f}")
            print(f"   Score min: {np.min(data['scores']):.4f}")
            print(f"   Score max: {np.max(data['scores']):.4f}")


# ============================================================================
# EXEMPLE D'UTILISATION
# ============================================================================

if __name__ == "__main__":
    """
    Script principal pour tester le syst√®me de recherche d'images similaires.
    
    INSTRUCTIONS:
    1. Modifiez 'dataset_path' avec le chemin vers votre dataset
    2. Le dataset doit contenir des images (jpg, png, etc.)
    3. Ajustez 'reference_idx' pour changer l'image de r√©f√©rence
    4. Modifiez 'k' pour changer le nombre de r√©sultats
    """
    
    # ‚öôÔ∏è CONFIGURATION
    dataset_path = "archive/animals/"  # √Ä MODIFIER
    reference_idx =  2000 # Index de l'image de r√©f√©rence
    k = 5  # Nombre d'images similaires √† trouver
    
    # üöÄ EX√âCUTION
    print("="*70)
    
    # Initialiser le syst√®me
    system = ImageSimilaritySystem(dataset_path, image_size=(128, 128))
    
    # Charger et pr√©traiter
    system.load_dataset()
    system.preprocess_images()
    
    # Comparer les diff√©rentes m√©thodes
    results = system.compare_methods(reference_idx, k=k)
    
    # Analyser les performances
    system.analyze_performance(results)
    
    print("\n‚úÖ Analyse termin√©e!")
    print("="*70)